# -*- coding: utf-8 -*-
"""A1-13-DL-PRAC-7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NnnFa6sBMeF0s4fHj-Eeh2DVhGNzAJ3m
"""

# Import necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout

import pandas as pd

# Load the dataset
file_path = "/content/Google_Stock_Price_Train (1).xlsx"
df = pd.read_excel(file_path)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler

import pandas as pd
# Load the dataset
file_path = "/content/Google_Stock_Price_Train (1).xlsx"
df = pd.read_excel(file_path)

# Convert Date column to datetime format
df["Date"] = pd.to_datetime(df["Date"], format="mixed", dayfirst=True)

# Sort the dataset by Date (if not already sorted)
df = df.sort_values(by="Date")

# Drop NaN values in Date column (if any)
df.dropna(subset=["Date"], inplace=True)

# Convert Open column to float, handle commas
df["Open"] = df["Open"].astype(str).str.replace(',', '').astype(float)

# Select only Open Price for LSTM model
df1 = df[['Open']].values

# Normalize the data
scaler = MinMaxScaler(feature_range=(0, 1))
df1_scaled = scaler.fit_transform(df1)

# Visualizing the Open Price Trend
plt.figure(figsize=(14,5))
plt.plot(df["Date"], df["Open"], label="Stock Open Price", color='blue')
plt.xlabel("Date")
plt.ylabel("Open Price")
plt.title("Google Stock Open Price Trend")
plt.legend()
plt.show()

# Print the first few rows to verify processing
print(df.head())

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout
from sklearn.model_selection import train_test_split

# Prepare input sequences and labels for LSTM
def create_sequences(data, time_step=60):
    X, Y = [], []
    for i in range(len(data) - time_step):
        X.append(data[i:i+time_step])
        Y.append(data[i+time_step])
    return np.array(X), np.array(Y)

# Define time step for sequence generation
time_step = 60

# Create sequences from scaled data
X, Y = create_sequences(df1_scaled, time_step)

# Reshape input to fit LSTM requirements: (samples, time steps, features)
X = X.reshape(X.shape[0], X.shape[1], 1)

# Split into training and validation sets
X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)

# Define LSTM model
model = Sequential([
    LSTM(50, return_sequences=True, input_shape=(time_step, 1)),
    Dropout(0.2),
    LSTM(50, return_sequences=True),
    Dropout(0.2),
    LSTM(50),
    Dropout(0.2),
    Dense(1)  # Output layer
])

# Compile model
model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
history = model.fit(X_train, Y_train, epochs=50, batch_size=32, validation_data=(X_val, Y_val), verbose=1)

# Predict on validation set
Y_pred = model.predict(X_val)

# Inverse transform predictions and actual values to original scale
Y_pred_original = scaler.inverse_transform(Y_pred)
Y_val_original = scaler.inverse_transform(Y_val.reshape(-1, 1))

# Plot Actual vs Predicted
plt.figure(figsize=(14,6))
plt.plot(Y_val_original, color='blue', label="Actual Price")
plt.plot(Y_pred_original, color='red', linestyle='dashed', label="Predicted Price")
plt.xlabel("Time")
plt.ylabel("Stock Price")
plt.title("Google Stock Price Prediction using LSTM")
plt.legend()
plt.show()

plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()
plt.title("Training vs Validation Loss")
plt.show()

